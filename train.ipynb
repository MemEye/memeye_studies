{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTMModel\n",
      "File \u001b[0;32m~/Desktop/memeye_studies/dataset.py:42\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[idx]\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#Save the dataset in train.pt\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m train_dataset\u001b[38;5;241m=\u001b[39m\u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m101\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(train_dataset,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain4.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     44\u001b[0m val_dataset\u001b[38;5;241m=\u001b[39mDataset(\u001b[38;5;241m121\u001b[39m,\u001b[38;5;241m123\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/memeye_studies/dataset.py:18\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[0;34m(self, start, end)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecognition_familar\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m csvs \u001b[38;5;129;01min\u001b[39;00m glob\u001b[38;5;241m.\u001b[39mglob(f\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/*.csv\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 18\u001b[0m         df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsvs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m         df\u001b[38;5;241m=\u001b[39mdf[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTH\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEA\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEL\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPI\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPR\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPG\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSF\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSR\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSA\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:586\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    571\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    572\u001b[0m     dialect,\n\u001b[1;32m    573\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    583\u001b[0m )\n\u001b[1;32m    584\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:488\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1047\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1046\u001b[0m     nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m-> 1047\u001b[0m     index, columns, col_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m col_dict:\n\u001b[1;32m   1051\u001b[0m             \u001b[38;5;66;03m# Any column is actually fine:\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py:224\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 224\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    226\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:801\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:880\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:1039\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/core/dtypes/common.py:1420\u001b[0m, in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1413\u001b[0m     \u001b[38;5;66;03m# Note: if other EA dtypes are ever held in HybridBlock, exclude those\u001b[39;00m\n\u001b[1;32m   1414\u001b[0m     \u001b[38;5;66;03m#  here too.\u001b[39;00m\n\u001b[1;32m   1415\u001b[0m     \u001b[38;5;66;03m# NB: need to check DatetimeTZDtype and not is_datetime64tz_dtype\u001b[39;00m\n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;66;03m#  to exclude ArrowTimestampUSDtype\u001b[39;00m\n\u001b[1;32m   1417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, DatetimeTZDtype)\n\u001b[0;32m-> 1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_extension_array_dtype\u001b[39m(arr_or_dtype) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   1421\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;124;03m    Check if an object is a pandas extension array type.\u001b[39;00m\n\u001b[1;32m   1423\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1465\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(arr_or_dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, arr_or_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from dataset import Dataset\n",
    "import torch\n",
    "from model import LSTMModel\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Training Accuracy:  0.3390783263509572\n",
      "Epoch:  0 Val Accuracy:  0.37119113573407203\n",
      "Epoch:  1 Training Accuracy:  0.3480935461632285\n",
      "Epoch:  1 Val Accuracy:  0.36795937211449675\n",
      "Epoch:  2 Training Accuracy:  0.37476799066659594\n",
      "Epoch:  2 Val Accuracy:  0.4039704524469067\n",
      "Epoch:  3 Training Accuracy:  0.3877605133372223\n",
      "Epoch:  3 Val Accuracy:  0.4113573407202216\n",
      "Epoch:  4 Training Accuracy:  0.42445776104364424\n",
      "Epoch:  4 Val Accuracy:  0.4132040627885503\n",
      "Epoch:  5 Training Accuracy:  0.41236676035424513\n",
      "Epoch:  5 Val Accuracy:  0.3425669436749769\n",
      "Epoch:  6 Training Accuracy:  0.4490109773558891\n",
      "Epoch:  6 Val Accuracy:  0.4422899353647276\n",
      "Epoch:  7 Training Accuracy:  0.4609959166357321\n",
      "Epoch:  7 Val Accuracy:  0.389196675900277\n",
      "Epoch:  8 Training Accuracy:  0.4798218168319457\n",
      "Epoch:  8 Val Accuracy:  0.41874422899353647\n",
      "Epoch:  9 Training Accuracy:  0.48602640929097946\n",
      "Epoch:  9 Val Accuracy:  0.46352723915050786\n",
      "Epoch:  10 Training Accuracy:  0.5036856339820757\n",
      "Epoch:  10 Val Accuracy:  0.4602954755309326\n",
      "Epoch:  11 Training Accuracy:  0.521556981492284\n",
      "Epoch:  11 Val Accuracy:  0.5069252077562327\n",
      "Epoch:  12 Training Accuracy:  0.5395343904120485\n",
      "Epoch:  12 Val Accuracy:  0.49630655586334255\n",
      "Epoch:  13 Training Accuracy:  0.5626557776952855\n",
      "Epoch:  13 Val Accuracy:  0.5249307479224377\n",
      "Epoch:  14 Training Accuracy:  0.555814816778915\n",
      "Epoch:  14 Val Accuracy:  0.5364727608494921\n",
      "Epoch:  15 Training Accuracy:  0.5913453889802196\n",
      "Epoch:  15 Val Accuracy:  0.5267774699907664\n",
      "Epoch:  16 Training Accuracy:  0.5885877923317601\n",
      "Epoch:  16 Val Accuracy:  0.5175438596491229\n",
      "Epoch:  17 Training Accuracy:  0.6054515564511852\n",
      "Epoch:  17 Val Accuracy:  0.579870729455217\n",
      "Epoch:  18 Training Accuracy:  0.6117622103197752\n",
      "Epoch:  18 Val Accuracy:  0.5992613111726686\n",
      "Epoch:  19 Training Accuracy:  0.6373760407275813\n",
      "Epoch:  19 Val Accuracy:  0.5983379501385041\n",
      "Epoch:  20 Training Accuracy:  0.6800127273691468\n",
      "Epoch:  20 Val Accuracy:  0.6301939058171745\n",
      "Epoch:  21 Training Accuracy:  0.6917325131250994\n",
      "Epoch:  21 Val Accuracy:  0.6532779316712835\n",
      "Epoch:  22 Training Accuracy:  0.7061568648247335\n",
      "Epoch:  22 Val Accuracy:  0.6717451523545707\n",
      "Epoch:  23 Training Accuracy:  0.7212706156864824\n",
      "Epoch:  23 Val Accuracy:  0.6966759002770083\n",
      "Epoch:  24 Training Accuracy:  0.7343691997666649\n",
      "Epoch:  24 Val Accuracy:  0.6865189289012004\n",
      "Epoch:  25 Training Accuracy:  0.7389298403775786\n",
      "Epoch:  25 Val Accuracy:  0.6934441366574331\n",
      "Epoch:  26 Training Accuracy:  0.7537784377154373\n",
      "Epoch:  26 Val Accuracy:  0.7040627885503232\n",
      "Epoch:  27 Training Accuracy:  0.758339078326351\n",
      "Epoch:  27 Val Accuracy:  0.7146814404432132\n",
      "Epoch:  28 Training Accuracy:  0.76714217531951\n",
      "Epoch:  28 Val Accuracy:  0.7211449676823638\n",
      "Epoch:  29 Training Accuracy:  0.7643315479662725\n",
      "Epoch:  29 Val Accuracy:  0.708679593721145\n",
      "Epoch:  30 Training Accuracy:  0.771914938749536\n",
      "Epoch:  30 Val Accuracy:  0.7299168975069252\n",
      "Epoch:  31 Training Accuracy:  0.7929681285464284\n",
      "Epoch:  31 Val Accuracy:  0.7132963988919667\n",
      "Epoch:  32 Training Accuracy:  0.7962560322426685\n",
      "Epoch:  32 Val Accuracy:  0.7349953831948292\n",
      "Epoch:  33 Training Accuracy:  0.8003393965105796\n",
      "Epoch:  33 Val Accuracy:  0.7539242843951985\n",
      "Epoch:  34 Training Accuracy:  0.8028848703399268\n",
      "Epoch:  34 Val Accuracy:  0.7437673130193906\n",
      "Epoch:  35 Training Accuracy:  0.8249986742323806\n",
      "Epoch:  35 Val Accuracy:  0.7506925207756233\n",
      "Epoch:  36 Training Accuracy:  0.8186880203637906\n",
      "Epoch:  36 Val Accuracy:  0.7465373961218836\n",
      "Epoch:  37 Training Accuracy:  0.8252638277562708\n",
      "Epoch:  37 Val Accuracy:  0.7714681440443213\n",
      "Epoch:  38 Training Accuracy:  0.8418624383518057\n",
      "Epoch:  38 Val Accuracy:  0.7807017543859649\n",
      "Epoch:  39 Training Accuracy:  0.8374078591504481\n",
      "Epoch:  39 Val Accuracy:  0.7774699907663897\n",
      "Epoch:  40 Training Accuracy:  0.8635519966060349\n",
      "Epoch:  40 Val Accuracy:  0.7793167128347184\n",
      "Epoch:  41 Training Accuracy:  0.8661505011401601\n",
      "Epoch:  41 Val Accuracy:  0.7867036011080333\n",
      "Epoch:  42 Training Accuracy:  0.8633398737869227\n",
      "Epoch:  42 Val Accuracy:  0.7853185595567868\n",
      "Epoch:  43 Training Accuracy:  0.8603701543193509\n",
      "Epoch:  43 Val Accuracy:  0.7839335180055401\n",
      "Epoch:  44 Training Accuracy:  0.8674232380548338\n",
      "Epoch:  44 Val Accuracy:  0.7899353647276085\n",
      "Epoch:  45 Training Accuracy:  0.8759611815241024\n",
      "Epoch:  45 Val Accuracy:  0.7843951985226223\n",
      "Epoch:  46 Training Accuracy:  0.8744232910855385\n",
      "Epoch:  46 Val Accuracy:  0.7797783933518005\n",
      "Epoch:  47 Training Accuracy:  0.8823248660974704\n",
      "Epoch:  47 Val Accuracy:  0.7862419205909511\n",
      "Epoch:  48 Training Accuracy:  0.8879991515087235\n",
      "Epoch:  48 Val Accuracy:  0.7793167128347184\n",
      "Epoch:  49 Training Accuracy:  0.8872567216418307\n",
      "Epoch:  49 Val Accuracy:  0.7959372114496768\n",
      "Epoch:  50 Training Accuracy:  0.8898021954711778\n",
      "Epoch:  50 Val Accuracy:  0.7899353647276085\n",
      "Epoch:  51 Training Accuracy:  0.8980749854165562\n",
      "Epoch:  51 Val Accuracy:  0.7723915050784856\n",
      "Epoch:  52 Training Accuracy:  0.8860370154319351\n",
      "Epoch:  52 Val Accuracy:  0.7945521698984302\n",
      "Epoch:  53 Training Accuracy:  0.8927719149387495\n",
      "Epoch:  53 Val Accuracy:  0.7843951985226223\n",
      "Epoch:  54 Training Accuracy:  0.9037492708278093\n",
      "Epoch:  54 Val Accuracy:  0.7719298245614035\n",
      "Epoch:  55 Training Accuracy:  0.9059765604284881\n",
      "Epoch:  55 Val Accuracy:  0.7686980609418282\n",
      "Epoch:  56 Training Accuracy:  0.8943628360820916\n",
      "Epoch:  56 Val Accuracy:  0.7853185595567868\n",
      "Epoch:  57 Training Accuracy:  0.9014689505223524\n",
      "Epoch:  57 Val Accuracy:  0.7742382271468145\n",
      "Epoch:  58 Training Accuracy:  0.9071432359336056\n",
      "Epoch:  58 Val Accuracy:  0.7733148661126501\n",
      "Epoch:  59 Training Accuracy:  0.8986583231691149\n",
      "Epoch:  59 Val Accuracy:  0.7705447830101569\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_classes=4\n",
    "dropout=0.1\n",
    "for second in [3]:\n",
    "    train=torch.load('train'+str(second)+'_dataloader.pt')\n",
    "    val=torch.load('val'+str(second)+'_dataloader.pt')\n",
    "    for layer in [3]:\n",
    "            for hidden_dim in [32]:\n",
    "                torch.manual_seed(0)\n",
    "                model=LSTMModel(10,hidden_dim,layer,output_classes,dropout,bidirectional=True)\n",
    "                optimizer=torch.optim.AdamW(model.parameters(),lr=0.01)\n",
    "                scheduler=torch.optim.lr_scheduler.StepLR(optimizer,step_size=20,gamma=0.3)\n",
    "                filename='modelBi'+str(second)+'/'+str(layer)+'_'+str(hidden_dim)\n",
    "                if not os.path.exists(filename):\n",
    "                    os.makedirs(filename)\n",
    "                f=open(filename+'/results.txt','w')\n",
    "                loss_arr=[]\n",
    "                training_accuracy=[]\n",
    "                val_accuracy=[]\n",
    "                for epoch in range(100):\n",
    "                    model.train()\n",
    "                    loss_sum=0\n",
    "                    for i,(x,y) in enumerate(train):\n",
    "                        optimizer.zero_grad()\n",
    "                        #Give input to bidirectional LSTM\n",
    "                        y_pred=model(x)\n",
    "                        loss=loss_fn(y_pred,y)\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        loss_sum+=loss.item()\n",
    "                    scheduler.step()\n",
    "                    loss_sum/=len(train)\n",
    "                    loss_arr.append(loss_sum)\n",
    "                    model.eval()\n",
    "                    correct=0\n",
    "                    total=0\n",
    "                    #Calculate accuracy per class \n",
    "                    accuracy_per_class=[0]*output_classes\n",
    "                    fp_per_class=[0]*output_classes\n",
    "                    fn_per_class=[0]*output_classes\n",
    "                    tp_per_class=[0]*output_classes\n",
    "                    tn_per_class=[0]*output_classes\n",
    "                    fp_rate_per_class=[0]*output_classes\n",
    "                    for i,(x,y) in enumerate(train):\n",
    "                        y_pred=model(x)\n",
    "                        _,predicted=torch.max(y_pred.data,1)\n",
    "                        total+=y.size(0)\n",
    "                        y=torch.max(y,1)[1]\n",
    "                        correct+=(predicted==y).sum().item()\n",
    "                        for i in range(len(y)):\n",
    "                            if y[i]==predicted[i]:\n",
    "                                tp_per_class[y[i]]+=1\n",
    "                                for j in range(output_classes):\n",
    "                                    if j!=y[i]:\n",
    "                                        tn_per_class[j]+=1\n",
    "                            else:\n",
    "                                fp_per_class[predicted[i]]+=1\n",
    "                                fn_per_class[y[i]]+=1\n",
    "                                for j in range(output_classes):\n",
    "                                    if j!=y[i] and j!=predicted[i]:\n",
    "                                        tn_per_class[j]+=1\n",
    "                    for i in range(output_classes):\n",
    "                        fp_rate_per_class[i]=fp_per_class[i]/(fp_per_class[i]+tn_per_class[i])\n",
    "                        accuracy_per_class[i]=tp_per_class[i]/(tp_per_class[i]+fn_per_class[i])\n",
    "                    print('Epoch: ',epoch,'Training Accuracy: ',correct/total)\n",
    "                    training_accuracy.append(correct/total)\n",
    "                    f.write('Epoch: '+str(epoch)+' Training Accuracy: '+str(correct/total)+'\\n')\n",
    "                    f.write('Accuracy per class: '+str(accuracy_per_class)+'\\n')\n",
    "                    f.write('False positive rate per class: '+str(fp_rate_per_class)+'\\n')\n",
    "                    f.write('False positive per class: '+str(fp_per_class)+'\\n')\n",
    "                    f.write('False negative per class: '+str(fn_per_class)+'\\n')\n",
    "                    f.write('True positive per class: '+str(tp_per_class)+'\\n')\n",
    "                    f.write('True negative per class: '+str(tn_per_class)+'\\n')\n",
    "                    f.write('\\n')\n",
    "                    correct=0\n",
    "                    total=0\n",
    "                    accuracy_per_class=[0]*output_classes\n",
    "                    fp_per_class=[0]*output_classes\n",
    "                    fn_per_class=[0]*output_classes\n",
    "                    tp_per_class=[0]*output_classes\n",
    "                    tn_per_class=[0]*output_classes\n",
    "                    fp_rate_per_class=[0]*output_classes\n",
    "                    for i,(x,y) in enumerate(val):\n",
    "                        y_pred=model(x)\n",
    "                        _,predicted=torch.max(y_pred.data,1)\n",
    "                        total+=y.size(0)\n",
    "                        y=torch.max(y,1)[1]\n",
    "                        correct+=(predicted==y).sum().item()\n",
    "                        for i in range(len(y)):\n",
    "                            if y[i]==predicted[i]:\n",
    "                                tp_per_class[y[i]]+=1\n",
    "                                for j in range(output_classes):\n",
    "                                    if j!=y[i]:\n",
    "                                        tn_per_class[j]+=1\n",
    "                            else:\n",
    "                                fp_per_class[predicted[i]]+=1\n",
    "                                fn_per_class[y[i]]+=1\n",
    "                                for j in range(output_classes):\n",
    "                                    if j!=y[i] and j!=predicted[i]:\n",
    "                                        tn_per_class[j]+=1\n",
    "                    for i in range(output_classes):\n",
    "                        fp_rate_per_class[i]=fp_per_class[i]/(fp_per_class[i]+tn_per_class[i])\n",
    "                        if tp_per_class[i]+fn_per_class[i]==0:\n",
    "                            accuracy_per_class[i]=1\n",
    "                        else:\n",
    "                            accuracy_per_class[i]=tp_per_class[i]/(tp_per_class[i]+fn_per_class[i])\n",
    "                    print('Epoch: ',epoch,'Val Accuracy: ',correct/total)\n",
    "                    val_accuracy.append(correct/total)\n",
    "                    f.write('Epoch: '+str(epoch)+' Val Accuracy: '+str(correct/total)+'\\n')\n",
    "                    f.write('Accuracy per class: '+str(accuracy_per_class)+'\\n')\n",
    "                    f.write('False positive rate per class: '+str(fp_rate_per_class)+'\\n')\n",
    "                    f.write('False positive per class: '+str(fp_per_class)+'\\n')\n",
    "                    f.write('False negative per class: '+str(fn_per_class)+'\\n')\n",
    "                    f.write('True positive per class: '+str(tp_per_class)+'\\n')\n",
    "                    f.write('True negative per class: '+str(tn_per_class)+'\\n')\n",
    "                    f.write('\\n')\n",
    "                    torch.save(model,filename+'/model'+str(epoch)+'.pt') \n",
    "                    #Early stopping\n",
    "                    if epoch>50 and val_accuracy[-1]<val_accuracy[-2] and training_accuracy[-1]-training_accuracy[-10]<0.01:\n",
    "                        break  \n",
    "                f.write('Best val accuracy: '+str(max(val_accuracy))+'\\n')\n",
    "                f.write('Epoch with best val accuracy: '+str(val_accuracy.index(max(val_accuracy)))+'\\n')\n",
    "                plt.plot(loss_arr)\n",
    "                plt.xlabel('Epoch')\n",
    "                plt.ylabel('Loss')\n",
    "                plt.savefig(filename+'/loss.png')\n",
    "                plt.close()\n",
    "                plt.plot(training_accuracy)\n",
    "                plt.xlabel('Epoch')\n",
    "                plt.ylabel('Training Accuracy')\n",
    "                plt.savefig(filename+'/training_accuracy.png')\n",
    "                plt.close()\n",
    "                plt.plot(val_accuracy)\n",
    "                plt.xlabel('Epoch')\n",
    "                plt.ylabel('Validation Accuracy')\n",
    "                plt.savefig(filename+'/val_accuracy.png')\n",
    "                f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
